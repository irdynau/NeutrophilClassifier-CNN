{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-Based Classification of Neutrophils in Microscopy Images (ResNet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torchvision.models import ResNet34_Weights\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths to directories\n",
    "healthy_dir = '/Users/irdynaumaira/Downloads/CompSci_MSc-project/Images/Healthy'\n",
    "nets_dir = '/Users/irdynaumaira/Downloads/CompSci_MSc-project/Images/NETs'\n",
    "class_names = ['Healthy', 'NETs']\n",
    "image_size = (224, 224)\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "def apply_clahe(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(image)\n",
    "\n",
    "# Load and preprocess data with CLAHE\n",
    "def load_data():\n",
    "    images, labels = [], []\n",
    "    for folder, label in zip([healthy_dir, nets_dir], [0, 1]):  # 0: Healthy, 1: NETs\n",
    "        for file in tqdm(os.listdir(folder)):\n",
    "            img_path = os.path.join(folder, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, image_size)\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            enhanced_image = apply_clahe(gray_image)\n",
    "            images.append(enhanced_image)\n",
    "            labels.append(label)\n",
    "    images = np.array(images, dtype='float32') / 255.0  # Normalize\n",
    "    labels = np.array(labels, dtype='int64')\n",
    "    return images, labels\n",
    "\n",
    "# Load the data\n",
    "images, labels = load_data()\n",
    "print(\"Data is successfully loaded.\")\n",
    "\n",
    "# Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images, self.labels = images, labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert grayscale to RGB\n",
    "        image = cv2.cvtColor(self.images[idx], cv2.COLOR_GRAY2RGB)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        return image, label\n",
    "\n",
    "# Data augmentation and transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(108),\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.7, 1.3)),\n",
    "    transforms.ColorJitter(contrast=(0.7, 1.3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  # Standard normalization for ImageNet\n",
    "])\n",
    "\n",
    "# Function to set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Function to load pre-trained ResNet34 model and modify for binary classification\n",
    "def load_resnet34():\n",
    "    weights = ResNet34_Weights.IMAGENET1K_V1\n",
    "    model = models.resnet34(weights=weights)\n",
    "    \n",
    "\n",
    "    # Modify the final fully connected layer for binary classification\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    # Freeze all layers except the final fully connected layer\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"fc\" in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images_batch, labels_batch in train_loader:\n",
    "            images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels_batch.size(0)\n",
    "            correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images_batch, labels_batch in val_loader:\n",
    "                images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "                outputs = model(images_batch)\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels_batch.size(0)\n",
    "                val_correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(100 * val_correct / val_total)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.2f}%, \"\n",
    "              f\"Val Acc: {val_accuracies[-1]:.2f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Seeds for experiments\n",
    "seeds = [42, 256, 282, 382, 404]\n",
    "\n",
    "# Initialize metrics lists\n",
    "all_train_accuracies = []\n",
    "all_val_accuracies = []\n",
    "all_test_accuracies = []\n",
    "all_test_precisions = []\n",
    "all_test_recalls = []\n",
    "all_test_f1s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nRunning with seed: {seed}\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Stratified splitting\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=seed, stratify=labels)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "        test_images, test_labels, test_size=0.5, random_state=seed, stratify=test_labels)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = CustomDataset(train_images, train_labels, transform)\n",
    "    val_dataset = CustomDataset(val_images, val_labels, transform)\n",
    "    test_dataset = CustomDataset(test_images, test_labels, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Load ResNet34 model\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "    # Freeze all layers except the final fully connected layer\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Send model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # Criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0015, weight_decay=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "    # Test evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images_batch, labels_batch in test_loader:\n",
    "            images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "            outputs = model(images_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "    # Accuracy and metrics\n",
    "    test_accuracy = 100 * np.sum(np.array(all_preds) == np.array(all_targets)) / len(all_targets)\n",
    "    all_test_accuracies.append(test_accuracy)\n",
    "\n",
    "    report = classification_report(all_targets, all_preds, target_names=class_names, output_dict=True)\n",
    "    all_test_precisions.append(report['weighted avg']['precision'])\n",
    "    all_test_recalls.append(report['weighted avg']['recall'])\n",
    "    all_test_f1s.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print(f\"Test Accuracy for seed {seed}: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix for Seed {seed}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    epochs_range = range(1, 101)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(epochs_range, val_accuracies, label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy for Seed {seed}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
    "    plt.title(f'Loss for Seed {seed}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and print average metrics\n",
    "def calculate_mean_and_std(values):\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    return mean, std\n",
    "\n",
    "metrics = {\n",
    "    \"Test Accuracy (%)\": all_test_accuracies,\n",
    "    \"Precision\": all_test_precisions,\n",
    "    \"Recall\": all_test_recalls,\n",
    "    \"F1-Score\": all_test_f1s,\n",
    "}\n",
    "\n",
    "for metric_name, values in metrics.items():\n",
    "    mean, std = calculate_mean_and_std(values)\n",
    "    print(f'Average {metric_name}: {mean:.2f} ± {std:.2f}')\n",
    "\n",
    "# Plot box plot for Test Accuracy across different seeds \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(all_test_accuracies, tick_labels=['Test Accuracy'], showmeans=True)\n",
    "plt.title('Test Accuracy Distribution Across Different Seeds')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot box plots for Precision, Recall, F1-Score across Different Seeds\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_data = [all_test_precisions, all_test_recalls, all_test_f1s]\n",
    "plt.boxplot(metrics_data, tick_labels=['Precision', 'Recall', 'F1-Score'], showmeans=True)\n",
    "plt.title('Performance Metrics Distribution Across Different Seeds')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
